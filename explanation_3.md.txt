The Huffman algorithm works by assigning codes that correspond to the relative frequency of each character for each character. 
The Huffman code can be of any length and does not require a prefix; therefore, this binary code can be visualized on a binary 
tree with each encoded character being stored in the leaves.

As, little background was supplied in the Udacity Huffman Coding Project, I followed the classical algorithm(s) for Huffman Coding. 
References are supplied in the code where needed. The idea I used was to use a priority queue using Pythonâ€™s heapq module to build 
the Huffman Tree. This seemed to be the idea overwhelming suggested in the literature I read. This also reduced the amount of code needed.

The time complexity of the Huffman algorithm is O(nlogn). By using a heap to store the weight of each tree, each iteration requires 
O(log n) time to place in the priority queue, and there are O(n) iterations, one for each item. The space complexity in building the 
Huffman Tree is O(#of distinct symbols in the data).